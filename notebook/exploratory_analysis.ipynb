{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f51633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatia\\AppData\\Local\\Temp\\ipykernel_20084\\3404048465.py:3: DtypeWarning: Columns (33,41,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['infos_basicas.telefone_recado', 'infos_basicas.telefone',\n",
      "       'infos_basicas.objetivo_profissional', 'infos_basicas.data_criacao',\n",
      "       'infos_basicas.inserido_por', 'infos_basicas.email',\n",
      "       'infos_basicas.local', 'infos_basicas.sabendo_de_nos_por',\n",
      "       'infos_basicas.data_atualizacao', 'infos_basicas.codigo_profissional',\n",
      "       ...\n",
      "       'embedding_290', 'embedding_291', 'embedding_292', 'embedding_293',\n",
      "       'embedding_294', 'embedding_295', 'embedding_296', 'embedding_297',\n",
      "       'embedding_298', 'embedding_299'],\n",
      "      dtype='object', length=350)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n",
    "print(df_applicants.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7b35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatia\\AppData\\Local\\Temp\\ipykernel_20084\\2706402534.py:6: DtypeWarning: Columns (33,41,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n",
      "C:\\Users\\tatia\\AppData\\Local\\Temp\\ipykernel_20084\\2706402534.py:7: DtypeWarning: Columns (17,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_vagas = pd.read_csv(\"../data/processed/vagas_processed.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo da coluna texto_unificado applicants:\n",
      "0     assistente administrativo\\n\\n\\nsantosbatista\\...\n",
      "1     formacao academica\\nensino medio 2o grau em e...\n",
      "2     objetivo area administrativa  financeira\\n\\nr...\n",
      "3     formacao\\nensino medio completo\\ninformatica ...\n",
      "4     ultima atualizacao em 09112021\\n sp\\n\\nensino...\n",
      "Name: texto_unificado, dtype: object\n",
      "Exemplo da coluna texto_unificado vagas:\n",
      "0     operation lead  operations lead\\n\\nroles  res...\n",
      "1     consultor ppqm senior consultor ppqm sr\\n\\n c...\n",
      "2     analista pljr c sql descricao  atividades\\n\\n...\n",
      "3     technical architect  11894809 descricaocoment...\n",
      "4     consultor sap authorization bca pleno  senior...\n",
      "Name: texto_unificado, dtype: object\n",
      "Embedding applicants (primeiras 5 linhas):\n",
      "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "0          0.0          0.0     0.000000     0.000000     0.000000   \n",
      "1          0.0          0.0     0.048650     0.000000     0.092556   \n",
      "2          0.0          0.0     0.000000     0.000000     0.000000   \n",
      "3          0.0          0.0     0.000000     0.000000     0.000000   \n",
      "4          0.0          0.0     0.036006     0.036984     0.000000   \n",
      "\n",
      "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
      "0     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "1     0.000000     0.046486     0.139097     0.089142     0.089681  ...   \n",
      "2     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "3     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "4     0.069693     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "\n",
      "   embedding_290  embedding_291  embedding_292  embedding_293  embedding_294  \\\n",
      "0            0.0            0.0       0.000000       0.000000            0.0   \n",
      "1            0.0            0.0       0.000000       0.248615            0.0   \n",
      "2            0.0            0.0       0.000000       0.073646            0.0   \n",
      "3            0.0            0.0       0.080635       0.094875            0.0   \n",
      "4            0.0            0.0       0.000000       0.000000            0.0   \n",
      "\n",
      "   embedding_295  embedding_296  embedding_297  embedding_298  embedding_299  \n",
      "0            0.0            0.0            0.0       0.000000            0.0  \n",
      "1            0.0            0.0            0.0       0.042602            0.0  \n",
      "2            0.0            0.0            0.0       0.000000            0.0  \n",
      "3            0.0            0.0            0.0       0.000000            0.0  \n",
      "4            0.0            0.0            0.0       0.031530            0.0  \n",
      "\n",
      "[5 rows x 300 columns]\n",
      "Embedding vagas (primeiras 5 linhas):\n",
      "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "0          0.0          0.0      0.00000          0.0          0.0   \n",
      "1          0.0          0.0      0.00000          0.0          0.0   \n",
      "2          0.0          0.0      0.00000          0.0          0.0   \n",
      "3          0.0          0.0      0.08076          0.0          0.0   \n",
      "4          0.0          0.0      0.00000          0.0          0.0   \n",
      "\n",
      "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
      "0          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "1          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "2          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "3          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "4          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "\n",
      "   embedding_290  embedding_291  embedding_292  embedding_293  embedding_294  \\\n",
      "0            0.0            0.0            0.0            0.0            0.0   \n",
      "1            0.0            0.0            0.0            0.0            0.0   \n",
      "2            0.0            0.0            0.0            0.0            0.0   \n",
      "3            0.0            0.0            0.0            0.0            0.0   \n",
      "4            0.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   embedding_295  embedding_296  embedding_297  embedding_298  embedding_299  \n",
      "0       0.124849       0.047457        0.05647            0.0            0.0  \n",
      "1       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "2       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "3       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "4       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "\n",
      "[5 rows x 300 columns]\n",
      "Soma dos embeddings do primeiro applicant: 4.548189312632716\n",
      "Soma dos embeddings da primeira vaga: 4.517496874976082\n",
      "Applicant embedding sum: 0\n",
      "Vaga embedding sum: 0\n",
      "Colunas embedding applicants: []\n",
      "Colunas embedding vagas: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Carregar os dados processados\n",
    "df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n",
    "df_vagas = pd.read_csv(\"../data/processed/vagas_processed.csv\")\n",
    "\n",
    "print(\"Exemplo da coluna texto_unificado applicants:\")\n",
    "print(df_applicants[\"texto_unificado\"].head())\n",
    "\n",
    "print(\"Exemplo da coluna texto_unificado vagas:\")\n",
    "print(df_vagas[\"texto_unificado\"].head())\n",
    "\n",
    "\n",
    "# Define as colunas de embedding\n",
    "embedding_cols_applicant = [col for col in df_applicants.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "embedding_cols_vaga = [col for col in df_vagas.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "\n",
    "print(\"Embedding applicants (primeiras 5 linhas):\")\n",
    "print(df_applicants[[col for col in df_applicants.columns if col.startswith('embedding_')]].head())\n",
    "\n",
    "print(\"Embedding vagas (primeiras 5 linhas):\")\n",
    "print(df_vagas[[col for col in df_vagas.columns if col.startswith('embedding_')]].head())\n",
    "\n",
    "print(\"Soma dos embeddings do primeiro applicant:\", \n",
    "      df_applicants.loc[0, [col for col in df_applicants.columns if col.startswith('embedding_')]].sum())\n",
    "\n",
    "print(\"Soma dos embeddings da primeira vaga:\", \n",
    "      df_vagas.loc[0, [col for col in df_vagas.columns if col.startswith('embedding_')]].sum())\n",
    "\n",
    "\n",
    "# Pega o embedding do primeiro applicant e primeira vaga\n",
    "applicant_embedding = df_applicants.loc[0, embedding_cols_applicant].values.reshape(1, -1)\n",
    "vaga_embedding = df_vagas.loc[0, embedding_cols_vaga].values.reshape(1, -1)\n",
    "\n",
    "print(\"Applicant embedding sum:\", np.sum(applicant_embedding))\n",
    "print(\"Vaga embedding sum:\", np.sum(vaga_embedding))\n",
    "\n",
    "embedding_cols_applicant = [col for col in df_applicants.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "embedding_cols_vaga = [col for col in df_vagas.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "\n",
    "print(\"Colunas embedding applicants:\", embedding_cols_applicant)\n",
    "print(\"Colunas embedding vagas:\", embedding_cols_vaga)\n",
    "\n",
    "similarity = cosine_similarity(applicant_embedding, vaga_embedding)[0][0]\n",
    "print(f\"Similaridade cosine entre primeiro applicant e vaga: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7900b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "modelo = joblib.load(\"../models/modelo_match.pkl\")\n",
    "print(modelo.n_features_in_)\n",
    "\n",
    "print(\"Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f292b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codigo_candidato', 'codigo_vaga', 'similarity', 'match']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo_candidato</th>\n",
       "      <th>codigo_vaga</th>\n",
       "      <th>similarity</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25632</td>\n",
       "      <td>4530</td>\n",
       "      <td>0.186729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25529</td>\n",
       "      <td>4530</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25364</td>\n",
       "      <td>4531</td>\n",
       "      <td>0.079623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25360</td>\n",
       "      <td>4531</td>\n",
       "      <td>0.090742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26338</td>\n",
       "      <td>4533</td>\n",
       "      <td>0.187220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24645</td>\n",
       "      <td>4533</td>\n",
       "      <td>0.213744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26361</td>\n",
       "      <td>4534</td>\n",
       "      <td>0.075380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26205</td>\n",
       "      <td>4534</td>\n",
       "      <td>0.069528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26003</td>\n",
       "      <td>4534</td>\n",
       "      <td>0.086330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25509</td>\n",
       "      <td>4534</td>\n",
       "      <td>0.014454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo_candidato  codigo_vaga  similarity  match\n",
       "0             25632         4530    0.186729      1\n",
       "1             25529         4530    0.072449      1\n",
       "2             25364         4531    0.079623      1\n",
       "3             25360         4531    0.090742      1\n",
       "4             26338         4533    0.187220      1\n",
       "5             24645         4533    0.213744      1\n",
       "6             26361         4534    0.075380      1\n",
       "7             26205         4534    0.069528      1\n",
       "8             26003         4534    0.086330      1\n",
       "9             25509         4534    0.014454      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/dataset_final.csv\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1757033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório atual: c:\\Users\\tatia\\decision-ai-recruiter\\notebook\n",
      "Arquivos em data: ['applicants.json', 'prospects.json', 'vagas.json']\n",
      "Arquivo ..\\data/raw\\prospects.json carregado com 14222 registros.\n",
      "Arquivo ..\\data/raw\\applicants.json carregado com 42482 registros.\n",
      "Arquivo ..\\data/raw\\vagas.json carregado com 14081 registros.\n",
      "Arquivos em data: ['applicants_processed.csv', 'dataset_final.csv', 'prospects_processed.csv', 'vagas_processed.csv']\n",
      "Arquivo ..\\data/processed\\applicants_processed.csv carregado com 42482 registros.\n",
      "Arquivo ..\\data/processed\\prospects_processed.csv carregado com 53759 registros.\n",
      "Arquivo ..\\data/processed\\vagas_processed.csv carregado com 14081 registros.\n",
      "Arquivo ..\\data/processed\\dataset_final.csv carregado com 98830 registros.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "print(\"Diretório atual:\", os.getcwd())\n",
    "\n",
    "# Caminho corrigido para a pasta 'data' que está no diretório pai\n",
    "data_folder_raw = os.path.join(\"..\", \"data/raw\")\n",
    "data_folder_process = os.path.join(\"..\", \"data/processed\")\n",
    "\n",
    "print(\"Arquivos em data:\", os.listdir(data_folder_raw))\n",
    "\n",
    "file_path = os.path.join(data_folder_raw, \"prospects.json\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_folder_raw, \"applicants.json\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_folder_raw, \"vagas.json\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Arquivos em data:\", os.listdir(data_folder_process))\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_folder_process, \"applicants_processed.csv\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = list(reader)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_folder_process, \"prospects_processed.csv\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = list(reader)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_folder_process, \"vagas_processed.csv\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = list(reader)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_folder_process, \"dataset_final.csv\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = list(reader)\n",
    "print(f\"Arquivo {file_path} carregado com {len(data)} registros.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499a4d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
