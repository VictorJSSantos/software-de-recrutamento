{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f51633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatia\\AppData\\Local\\Temp\\ipykernel_20084\\3404048465.py:3: DtypeWarning: Columns (33,41,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['infos_basicas.telefone_recado', 'infos_basicas.telefone',\n",
      "       'infos_basicas.objetivo_profissional', 'infos_basicas.data_criacao',\n",
      "       'infos_basicas.inserido_por', 'infos_basicas.email',\n",
      "       'infos_basicas.local', 'infos_basicas.sabendo_de_nos_por',\n",
      "       'infos_basicas.data_atualizacao', 'infos_basicas.codigo_profissional',\n",
      "       ...\n",
      "       'embedding_290', 'embedding_291', 'embedding_292', 'embedding_293',\n",
      "       'embedding_294', 'embedding_295', 'embedding_296', 'embedding_297',\n",
      "       'embedding_298', 'embedding_299'],\n",
      "      dtype='object', length=350)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n",
    "print(df_applicants.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7b35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatia\\AppData\\Local\\Temp\\ipykernel_20084\\2706402534.py:6: DtypeWarning: Columns (33,41,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n",
      "C:\\Users\\tatia\\AppData\\Local\\Temp\\ipykernel_20084\\2706402534.py:7: DtypeWarning: Columns (17,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_vagas = pd.read_csv(\"../data/processed/vagas_processed.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo da coluna texto_unificado applicants:\n",
      "0     assistente administrativo\\n\\n\\nsantosbatista\\...\n",
      "1     formacao academica\\nensino medio 2o grau em e...\n",
      "2     objetivo area administrativa  financeira\\n\\nr...\n",
      "3     formacao\\nensino medio completo\\ninformatica ...\n",
      "4     ultima atualizacao em 09112021\\n sp\\n\\nensino...\n",
      "Name: texto_unificado, dtype: object\n",
      "Exemplo da coluna texto_unificado vagas:\n",
      "0     operation lead  operations lead\\n\\nroles  res...\n",
      "1     consultor ppqm senior consultor ppqm sr\\n\\n c...\n",
      "2     analista pljr c sql descricao  atividades\\n\\n...\n",
      "3     technical architect  11894809 descricaocoment...\n",
      "4     consultor sap authorization bca pleno  senior...\n",
      "Name: texto_unificado, dtype: object\n",
      "Embedding applicants (primeiras 5 linhas):\n",
      "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "0          0.0          0.0     0.000000     0.000000     0.000000   \n",
      "1          0.0          0.0     0.048650     0.000000     0.092556   \n",
      "2          0.0          0.0     0.000000     0.000000     0.000000   \n",
      "3          0.0          0.0     0.000000     0.000000     0.000000   \n",
      "4          0.0          0.0     0.036006     0.036984     0.000000   \n",
      "\n",
      "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
      "0     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "1     0.000000     0.046486     0.139097     0.089142     0.089681  ...   \n",
      "2     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "3     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "4     0.069693     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "\n",
      "   embedding_290  embedding_291  embedding_292  embedding_293  embedding_294  \\\n",
      "0            0.0            0.0       0.000000       0.000000            0.0   \n",
      "1            0.0            0.0       0.000000       0.248615            0.0   \n",
      "2            0.0            0.0       0.000000       0.073646            0.0   \n",
      "3            0.0            0.0       0.080635       0.094875            0.0   \n",
      "4            0.0            0.0       0.000000       0.000000            0.0   \n",
      "\n",
      "   embedding_295  embedding_296  embedding_297  embedding_298  embedding_299  \n",
      "0            0.0            0.0            0.0       0.000000            0.0  \n",
      "1            0.0            0.0            0.0       0.042602            0.0  \n",
      "2            0.0            0.0            0.0       0.000000            0.0  \n",
      "3            0.0            0.0            0.0       0.000000            0.0  \n",
      "4            0.0            0.0            0.0       0.031530            0.0  \n",
      "\n",
      "[5 rows x 300 columns]\n",
      "Embedding vagas (primeiras 5 linhas):\n",
      "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "0          0.0          0.0      0.00000          0.0          0.0   \n",
      "1          0.0          0.0      0.00000          0.0          0.0   \n",
      "2          0.0          0.0      0.00000          0.0          0.0   \n",
      "3          0.0          0.0      0.08076          0.0          0.0   \n",
      "4          0.0          0.0      0.00000          0.0          0.0   \n",
      "\n",
      "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
      "0          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "1          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "2          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "3          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "4          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "\n",
      "   embedding_290  embedding_291  embedding_292  embedding_293  embedding_294  \\\n",
      "0            0.0            0.0            0.0            0.0            0.0   \n",
      "1            0.0            0.0            0.0            0.0            0.0   \n",
      "2            0.0            0.0            0.0            0.0            0.0   \n",
      "3            0.0            0.0            0.0            0.0            0.0   \n",
      "4            0.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "   embedding_295  embedding_296  embedding_297  embedding_298  embedding_299  \n",
      "0       0.124849       0.047457        0.05647            0.0            0.0  \n",
      "1       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "2       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "3       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "4       0.000000       0.000000        0.00000            0.0            0.0  \n",
      "\n",
      "[5 rows x 300 columns]\n",
      "Soma dos embeddings do primeiro applicant: 4.548189312632716\n",
      "Soma dos embeddings da primeira vaga: 4.517496874976082\n",
      "Applicant embedding sum: 0\n",
      "Vaga embedding sum: 0\n",
      "Colunas embedding applicants: []\n",
      "Colunas embedding vagas: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Carregar os dados processados\n",
    "df_applicants = pd.read_csv(\"../data/processed/applicants_processed.csv\")\n",
    "df_vagas = pd.read_csv(\"../data/processed/vagas_processed.csv\")\n",
    "\n",
    "print(\"Exemplo da coluna texto_unificado applicants:\")\n",
    "print(df_applicants[\"texto_unificado\"].head())\n",
    "\n",
    "print(\"Exemplo da coluna texto_unificado vagas:\")\n",
    "print(df_vagas[\"texto_unificado\"].head())\n",
    "\n",
    "\n",
    "# Define as colunas de embedding\n",
    "embedding_cols_applicant = [col for col in df_applicants.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "embedding_cols_vaga = [col for col in df_vagas.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "\n",
    "print(\"Embedding applicants (primeiras 5 linhas):\")\n",
    "print(df_applicants[[col for col in df_applicants.columns if col.startswith('embedding_')]].head())\n",
    "\n",
    "print(\"Embedding vagas (primeiras 5 linhas):\")\n",
    "print(df_vagas[[col for col in df_vagas.columns if col.startswith('embedding_')]].head())\n",
    "\n",
    "print(\"Soma dos embeddings do primeiro applicant:\", \n",
    "      df_applicants.loc[0, [col for col in df_applicants.columns if col.startswith('embedding_')]].sum())\n",
    "\n",
    "print(\"Soma dos embeddings da primeira vaga:\", \n",
    "      df_vagas.loc[0, [col for col in df_vagas.columns if col.startswith('embedding_')]].sum())\n",
    "\n",
    "\n",
    "# Pega o embedding do primeiro applicant e primeira vaga\n",
    "applicant_embedding = df_applicants.loc[0, embedding_cols_applicant].values.reshape(1, -1)\n",
    "vaga_embedding = df_vagas.loc[0, embedding_cols_vaga].values.reshape(1, -1)\n",
    "\n",
    "print(\"Applicant embedding sum:\", np.sum(applicant_embedding))\n",
    "print(\"Vaga embedding sum:\", np.sum(vaga_embedding))\n",
    "\n",
    "embedding_cols_applicant = [col for col in df_applicants.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "embedding_cols_vaga = [col for col in df_vagas.columns if col.startswith(\"texto_unificado_tfidf_\")]\n",
    "\n",
    "print(\"Colunas embedding applicants:\", embedding_cols_applicant)\n",
    "print(\"Colunas embedding vagas:\", embedding_cols_vaga)\n",
    "\n",
    "similarity = cosine_similarity(applicant_embedding, vaga_embedding)[0][0]\n",
    "print(f\"Similaridade cosine entre primeiro applicant e vaga: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7900b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "modelo = joblib.load(\"../models/modelo_match.pkl\")\n",
    "print(modelo.n_features_in_)\n",
    "\n",
    "print(\"Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f292b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/modelo_treinado.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m MODEL_PATH = \u001b[33m\"\u001b[39m\u001b[33mmodels/modelo_treinado.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Teste: vetor de features de exemplo\u001b[39;00m\n\u001b[32m      9\u001b[39m exemplo_features = np.array([[\u001b[32m0.1\u001b[39m, \u001b[32m0.2\u001b[39m, \u001b[32m0.3\u001b[39m]])  \u001b[38;5;66;03m# ajuste para o tamanho certo\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tatia\\software-de-recrutamento\\venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models/modelo_treinado.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "MODEL_PATH = \"models/modelo_treinado.pkl\"\n",
    "\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "# Teste: vetor de features de exemplo\n",
    "exemplo_features = np.array([[0.1, 0.2, 0.3]])  # ajuste para o tamanho certo\n",
    "\n",
    "pred = model.predict(exemplo_features)\n",
    "print(f\"Predição: {pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
